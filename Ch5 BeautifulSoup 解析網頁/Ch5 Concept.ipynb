{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective\n",
    "===\n",
    "不使用瀏覽器開啟網頁\n",
    "\n",
    "## Resources\n",
    "\n",
    "**圖片顯示**\n",
    "1. [OpenCV basic techniques of read and show images](https://blog.gtwang.org/programming/opencv-basic-image-read-and-write-tutorial/)\n",
    "\n",
    "**Scrapy爬蟲和資料處理**\n",
    "1. [IT邦 - 鐵人30天](https://ithelp.ithome.com.tw/users/20107514/ironman/1919?page=1)\n",
    "\n",
    "2. [httpbin](https://httpbin.org/#/Images/get_image_jpeg) \n",
    "\n",
    "**SyntaxError: EOL...**\n",
    "\n",
    "[Solution - stackoverflow](https://stackoverflow.com/questions/3561691/python-syntaxerror-eol-while-scanning-string-literal)\n",
    "\n",
    "**Webtachniques**\n",
    "\n",
    "[爬蟲常用技巧](https://titangene.github.io/article/python-crawler-note.html)\n",
    "\n",
    "\n",
    "## Problem \n",
    "14 放圖片 5-13\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. 解析網站使用 BeautifulSoup 模組\n",
    "\n",
    "前述章節講述如何**下載 HTML 原始檔案**<br>\n",
    "這裡要**利用 Beautifulsoup 解析 HTML 文件**<br>\n",
    "\n",
    "```python\n",
    "# 導入 beautifulsoup 模組\n",
    "import bs4 \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立 Beautifulsoup 物件\n",
    "> objSoup = bs4.BeautifulSoup(htmlFile.text, 'lxml')\n",
    "\n",
    "\n",
    "將網頁內容的 Response 物件傳給 bs4.BeautifulSoup() 的方法，就可以建立 bs4 物件<br>\n",
    "而 'lxml' 速度快，相容性佳，這是本書採用的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch5_1.py\n",
    "import requests, bs4\n",
    "# 或 from bs4 import BeautifulSoup\n",
    "\n",
    "# 請求下載 url 內容\n",
    "htmlFile = requests.get('http://www.deepmind.com.tw')\n",
    "# 1. 建立 Beautifulsoup 物件 - (objSoup)\n",
    "# 2. 解讀 HTML 文件(text)方式，並利用 \"lxml\" 的方法解析 HTML 文件\n",
    "objSoup = bs4.BeautifulSoup(htmlFile.text, 'lxml')\n",
    "print(\"列印BeautifulSoup物件資料型態 \", type(objSoup))\n",
    "print(objSoup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 基本 HTML 文件解析 (myhtml.html)\n",
    "\n",
    "html.text 是網頁內容的 Response 物件，先利用 BeautifulSoup 解析此文件。<br>\n",
    "可以從 print(objSoup) 中，了解到整個**節點樹**<br>\n",
    "\n",
    "```python\n",
    "mthtml.html = \n",
    "<!doctype html>\n",
    "<html>\n",
    "<head>\n",
    "   <meta charset=\"utf-8\">\n",
    "   <title>洪錦魁著作</title>\n",
    "   <style>\n",
    "      h1#author { width:400px; height:50px; text-align:center;\n",
    "\t     background:linear-gradient(to right,yellow,green);\n",
    "      }\n",
    "\t  h1#content { width:400px; height:50px;\n",
    "\t\t background:linear-gradient(to right,yellow,red); \n",
    "      }\n",
    "      section { background:linear-gradient(to right bottom,yellow,gray); }\n",
    "   </style>\n",
    "</head>\n",
    "<body>\n",
    "<h1 id=\"author\">洪錦魁</h1>\n",
    "<img src=\"hung.jpg\" width=\"100\">\n",
    "<section>\n",
    "   <h1 id=\"content\">一個人的極境旅行 - 南極大陸北極海</h1>\n",
    "   <p>2015/2016年<strong>洪錦魁</strong>一個人到南極</p>\n",
    "   <img src=\"travel.jpg\" width=\"300\">\n",
    "</section>\n",
    "<section>\n",
    "   <h1 id=\"content\">HTML5+CSS3王者歸來</h1>\n",
    "   <p>本書講解網頁設計使用HTML5+CSS3</p>\n",
    "   <img src=\"html5.jpg\" width=\"300\">\n",
    "</section>\n",
    "</body>\n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch5_2.py\n",
    "import bs4\n",
    "\n",
    "# 將 myhtml.html 打開，並以 utf-8 方法解譯，放入 htmlFile 內\n",
    "htmlFile = open('myhtml.html', encoding = 'utf-8')\n",
    "# 將 htmlFile 利用 \"lxml\" 的方法解析 HTML 文件，並存入 objSoup 物件\n",
    "objSoup = bs4.BeautifulSoup(htmlFile, 'lxml')\n",
    "print(\"列印BeautifulSoup物件資料型態: \", type(objSoup))\n",
    "# 輸出 objSoup 內的資料\n",
    "print('\\n',objSoup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 網頁標題 title 屬性 (objSoup.title())\n",
    "\n",
    "BeautifulSoup 物件的 title 屬性可以傳回網頁標題的 \"title\" 標籤內容<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch5_3.py\n",
    "import bs4\n",
    "\n",
    "# 將 myhtml.html 打開，並以 utf-8 方法解譯，放入 htmlFile 內\n",
    "htmlFile = open('myhtml.html', encoding = 'utf-8')\n",
    "# 將 htmlFile 利用 \"lxml\" 的方法解析 HTML 文件，並存入 objSoup 物件\n",
    "objSoup = bs4.BeautifulSoup(htmlFile, 'lxml')\n",
    "print(\"物件類型 =  \", type(objSoup))\n",
    "# 列印 title\n",
    "print('列印 title = ', objSoup.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 去除標籤傳回文字 text 屬性\n",
    "\n",
    "解析了 HTML 文件，但傳回解晰的結果是一個 HTML 的標籤，不過我們可以使用 text 屬性獲得此標籤的內容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch5_4.py\n",
    "import bs4\n",
    "\n",
    "# 打開 myhtml.html file，並以 utf-8 方法解譯\n",
    "htmlFile = open('myhtml.html', encoding='utf-8')\n",
    "# 將 htmlFile 利用 'lxml' 的方法解析 HTML 解析文件，並存入 bs4 物件(objSoup)\n",
    "objSoup = bs4.BeautifulSoup(htmlFile, 'lxml')\n",
    "print(\"列印title = \", objSoup.title)\n",
    "# 去除 HTML tag 的內容，只保留 tag 內 text 的內容\n",
    "print(\"title內容 = \", objSoup.title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 傳回所找尋第一個符合的標籤 find()\n",
    "\n",
    "此函數可以搜尋 HTML 文件內第一個符合的標籤內容<br>\n",
    "EX: ObjSoup.find('h1') 是要找第一個 h1 的標籤<br>\n",
    "\n",
    "我們可以利用 text/string 屬性傳回內容<br>\n",
    "EX: objTag.text, objTag.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch5_5.py\n",
    "import bs4\n",
    "# 打開 myhtml.html，並且利用 utf-8 方法解析\n",
    "htmlFile = open('myhtml.html', encoding = 'utf-8')\n",
    "# 利用 bs4 的 lxml 方法解析網頁內容，並存入 bs4 物件\n",
    "objSoup = bs4.BeautifulSoup(htmlFile, 'lxml')\n",
    "# 找尋 objSoup 中的\"第一個\" h1，並存入 objTag\n",
    "objTag = objSoup.find('h1')\n",
    "print('資料型態: ', type(objTag))\n",
    "print('列印 Tag: ', objTag)\n",
    "# 找尋 objTag.text 和 objTag.string 的不同\n",
    "print('Text 屬性內容: ', objTag.text)\n",
    "print('String 屬性內容: ', objTag.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 傳回掃找尋都符號內容 find_all()\n",
    "\n",
    "此函數可以找尋 HTML 文件內符合的標籤內容<br>\n",
    "如果找到了就傳回**標籤內容**，沒有找到就傳回**空串列**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch5_6.py\n",
    "import bs4\n",
    "\n",
    "# 打開 myhtml.html，並利用 utf-8 方法解析 HTML 文件\n",
    "htmlFile = open('myhtml.html', encoding='utf-8')\n",
    "# 利用 bs4 內 lxml 方法解析 HTML 文件，並存入 bs4 物件\n",
    "objSoup = bs4.BeautifulSoup(htmlFile, 'lxml')\n",
    "# 找尋 objSoup 內的 Tag (\"h1\")，並存入 ObjTag中\n",
    "objTag = objSoup.find_all('h1')\n",
    "print(\"資料型態    = \", type(objTag))     # 列印資料型態\n",
    "print(\"列印Tag串列 = \", objTag)           # 列印串列\n",
    "print(\"\\n以下是列印串列元素 : \")\n",
    "\n",
    "# 將 ObjTag中的\n",
    "for data in objTag:                       # 列印串列元素內容\n",
    "    print(data.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find_all(), Limit 節點數量\n",
    "限制找尋最多 n 個標籤節點: limit = n <br>\n",
    "限制找尋次一層次的節點: recursive = False<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch5_6_1.py\n",
    "import bs4\n",
    "\n",
    "# 打開 myhttml.html 並利用 utf-8 解析文件\n",
    "htmlFile = open('myhtml.html', encoding = 'utf-8')\n",
    "# 使用 bs4 lxml方法解析文件，並將之存為 bs4 obj\n",
    "objSoup = bs4.BeautifulSoup(htmlFile, 'lxml')\n",
    "# 找尋 obj 內的 tag 'h1'，並限制只能找 2 層\n",
    "objTag = objSoup.find_all('h1', limit = 2, recursive = True)\n",
    "# 列印串列元素內容\n",
    "for data in objTag:                       \n",
    "    print(data.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 認識 HTML 元素內容屬性與 getText()\n",
    "\n",
    "HTML 有3種元素:\n",
    "1. textContent: 內容，不含任何標籤碼\n",
    "2. innerHTML: 元素內容，含子標籤碼，但是不含本身標籤碼\n",
    "3. outerHTML: 元素內容，含子標籤碼，也含本身標籤碼\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch5_7.py\n",
    "# 目標>> 資料型態、列印 Tag 串列，使用 text 屬性列印內容，使用gettext()方法列印串列元素\n",
    "import bs4\n",
    "\n",
    "# 打開 myhttml.html 並利用 utf-8 解析文件\n",
    "htmlFile = open('myhtml.html', encoding = 'utf-8')\n",
    "# 使用 bs4 lxml方法解析文件，並將之存為 bs4 obj\n",
    "objSoup = bs4.BeautifulSoup(htmlFile, 'lxml')\n",
    "# print(objSoup)\n",
    "# 找尋 obj 內的 tag 'h1'\n",
    "objTag = objSoup.find_all('h1')\n",
    "print('資料型態: ', type(objTag))\n",
    "print('列印 Tag 串列: ', objTag)\n",
    "print('\\n使用 text 屬性列印標籤文字: ')\n",
    "for data in objTag:\n",
    "    print(data.text)\n",
    "print('\\n使用 gettext()方法列印串列元素: ')\n",
    "for data in objTag:\n",
    "    print(data.getText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch5_7_1.py\n",
    "# 目標找尋 id = 'author'\n",
    "import bs4\n",
    "\n",
    "# 打開 nyheml.html 並利用 utf-8 方法解析\n",
    "htmlFile = open('myhtml.html', encoding = 'utf-8')\n",
    "# 利用 bs4 lxml 方法解析，並存入 bs4 物件\n",
    "objSoup = bs4.BeautifulSoup(htmlFile, 'lxml')\n",
    "# 在 bs4 物件中找 id = 'author' 的 Tag\n",
    "objTag = objSoup.find(id = 'author')\n",
    "print(objTag)\n",
    "print(objTag.getText())\n",
    "print(objTag.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. 搜尋函數有 id = 'content' 的節點<br>\n",
    "會發現\n",
    "```python\n",
    "objTag = objSoup.find_all(id = 'content')\n",
    "# 由於 len(id = 'content') > 1，所以不能列印出全部\n",
    "print(objTag.getText())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import bs4 \n",
    "# ch5_7_2.py\n",
    "\n",
    "# 打開 nyheml.html 並利用 utf-8 方法解析\n",
    "htmlFile = open('myhtml.html', encoding = 'utf-8')\n",
    "# 利用 bs4 lxml 方法解析，並存入 bs4 物件\n",
    "objSoup = bs4.BeautifulSoup(htmlFile, 'lxml')\n",
    "# 在 bs4 物件中找所有 id = 'content' 的 Tag\n",
    "objTag = objSoup.find_all(id = 'content')\n",
    "# 由於 len(id = 'content') > 1，所以不能列印，程式會 broken\n",
    "try: \n",
    "    print(objTag.text)\n",
    "    print(objTag.geText())\n",
    "except Exception:\n",
    "    print(\"we can't utilize the text&getText() method\")\n",
    "\n",
    "print('\\n這是利用 for-loop\\n' + '-' * 70)\n",
    "for data in objTag:\n",
    "    print(data)\n",
    "    print(data.getText())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 搜索標籤內有 '-'，利用 attrs 參數處理\n",
    "有些網站設計屬性會有 'data-*' 含有 '-' 之類的屬性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch5_7_3.py\n",
    "import bs4\n",
    "\n",
    "# htmlFile = open('myhtml.html', encoding = 'utf-8')\n",
    "htmlFile = \"<div book-info='deepmind'>深智數位</div>\"\n",
    "# 利用 bs4 lxml 解析 htmlFile\n",
    "objSoup = bs4.BeautifulSoup(htmlFile, 'lxml')\n",
    "# 找尋 bs4 物件內 'book-info' = 'deepmind'\n",
    "tag = objSoup.find(attrs = {'book-info': 'deepmind'})\n",
    "print(tag)\n",
    "print(tag.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 使用 find() 或 find_all() 執行 CSS 的搜尋 (註1)\n",
    "class 由於是 python 的保留字，我們可以再用 find() 和 find_all()時，使用 **class_ **代表或者是直接不用 **class_** <br>\n",
    "\n",
    "我們定義了\n",
    "```python\n",
    "htmlFile = \"<h1 class = 'boldtext'>深智數位</h1>\"\n",
    "``` \n",
    "```python\n",
    "# 2 種找尋 Tag 方法都可行\n",
    "tag = objSoup.find('h1', class_ = 'boldtext')\n",
    "tag = objSoup.find('h1', 'boldtext')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch5_7_4.py\n",
    "import bs4\n",
    "\n",
    "htmlFile = \"\"\"<h1 class = 'boldtext'>深智數位</h1><h1 class = 'text'>洪錦魁</h1>\n",
    "\"\"\"\n",
    "# 利用 bs4 lxml 方法解析，並存入 bs4 物件\n",
    "objSoup = bs4.BeautifulSoup(htmlFile, 'lxml')\n",
    "# 找尋 bs4 物件內 Tag = 'h1' 且 class_ = 'boldtext'\n",
    "tag = objSoup.find_all('h1', class_ = 'boldtext')\n",
    "try:\n",
    "    print(tag)\n",
    "    # 因為 len(tag) > 1，所以無法列印出 \n",
    "    print(tag.text)\n",
    "    \n",
    "except AttributeError:\n",
    "    print('Fail')\n",
    "    \n",
    "    for data in tag:\n",
    "        print(data.getText())\n",
    "    \n",
    "print('-'*70)\n",
    "# 找尋 bs4 物件內 Tag = 'h1' 且 class_ = 'boldtext'\n",
    "tag = objSoup.find_all('h1', 'boldtext')\n",
    "try:\n",
    "    print(tag)        \n",
    "    # 因為 len(tag) > 1，所以無法列印出 \n",
    "    print(tag.text)\n",
    "    \n",
    "except AttributeError:\n",
    "    print('Fail')\n",
    "\n",
    "    for data in tag:\n",
    "        print(data.getText())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 搜尋部分字串符合的節點 re.compile('text') \n",
    "\n",
    "我們定義了\n",
    "```python\n",
    "htmlFile = \"\"\"<h1 class = 'boldtext'>深智數位</h1>, <h1 class = 'text'>洪錦魁</h1>\n",
    "\"\"\"\n",
    "```\n",
    "```python\n",
    "# 利用此方法找所有 Tag 有符合 class 內的字串有 text\n",
    "tag = objSoup.find_all('h1', class_ = re.compile('text'))\n",
    "tag = objSoup.find_all('h1', re.compile('text'))\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch5_7_4.py\n",
    "import bs4\n",
    "import re\n",
    "\n",
    "htmlFile = \"\"\"<h1 class = 'boldtext'>深智數位</h1>\\\n",
    "                <h1 class = 'text'>洪錦魁</h1>\n",
    "\"\"\"\n",
    "# 利用 bs4 lxml 方法解析，並存入 bs4 物件\n",
    "objSoup = bs4.BeautifulSoup(htmlFile, 'lxml')\n",
    "# 找尋 bs4 物件內 Tag = 'h1' 且 class_ = 'boldtext'\n",
    "tag = objSoup.find_all('h1', class_ = re.compile('text'))\n",
    "for data in tag:\n",
    "    print(data)\n",
    "    print(data.text)\n",
    "\n",
    "print('-'*70)\n",
    "# 找尋 bs4 物件內 Tag = 'h1' 且 class_ = 'boldtext'\n",
    "tag = objSoup.find_all('h1', re.compile('text'))\n",
    "\n",
    "try:\n",
    "    print(tag)\n",
    "    # 因為 len(tag) > 1，所以無法列印出 \n",
    "    print(tag.text)\n",
    "    \n",
    "except AttributeError:\n",
    "    print('Fail')\n",
    "    for data in tag:\n",
    "        print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 比對 CSS 內多種屬性\n",
    "\n",
    "CSS 屬性應用中，有些是多個屬性\n",
    "```python\n",
    "# 屬性間有空格，代表有多個屬性(bold, italic)\n",
    "class = \"bold italic\"\n",
    "```\n",
    "\n",
    "只要有一個屬性比對成功就算成功!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch5_7_6.py\n",
    "import bs4\n",
    "import re\n",
    "\n",
    "htmlFile = \"<h1 class='bold italic'>深智數位</h1>\"\n",
    "# 利用 bs4 lxml 方法解析，並存入 bs4 物件\n",
    "objSoup = bs4.BeautifulSoup(htmlFile, 'lxml')\n",
    "# 找尋 bs4 物件內 Tag = 'h1' 且 class_ = 'bold'\n",
    "tag = objSoup.find('h1', class_='bold')\n",
    "print(tag)\n",
    "print(tag.text)\n",
    "print('-'*70)\n",
    "# 找尋 bs4 物件內 Tag = 'h1' 且 class_ = 'italic'\n",
    "tag = objSoup.find('h1', class_='italic')\n",
    "print(tag)\n",
    "print(tag.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Select() CSS選擇器(selector)的觀念找尋元素\n",
    "\n",
    "如果從 bs4 物件中，找到回傳的是串列(list)，select()特色是可以一次找尋**所有**相符的元素。<br>\n",
    "\n",
    "EX: bs4 物件內有2個東西\n",
    "```python\n",
    "htmlFile = \"\"\"<h1 class = 'boldtext'>深智數位</h1>, <h1 class = 'text'>洪錦魁</h1>\n",
    "\"\"\"\n",
    "```\n",
    "有圖片\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<title>洪錦魁著作</title>\n",
      "<style>\n",
      "      h1#author { width:400px; height:50px; text-align:center;\n",
      "\t     background:linear-gradient(to right,yellow,green);\n",
      "      }\n",
      "\t  h1#content { width:400px; height:50px;\n",
      "\t\t background:linear-gradient(to right,yellow,red); \n",
      "      }\n",
      "      section { background:linear-gradient(to right bottom,yellow,gray); }\n",
      "   </style>\n",
      "</head>\n",
      "<body>\n",
      "<h1 id=\"author\">洪錦魁</h1>\n",
      "<img src=\"hung.jpg\" width=\"100\"/>\n",
      "<section>\n",
      "<h1 id=\"content\">一個人的極境旅行 - 南極大陸北極海</h1>\n",
      "<p>2015/2016年<strong>洪錦魁</strong>一個人到南極</p>\n",
      "<img src=\"travel.jpg\" width=\"300\"/>\n",
      "</section>\n",
      "<section>\n",
      "<h1 id=\"content\">HTML5+CSS3王者歸來</h1>\n",
      "<p>本書講解網頁設計使用HTML5+CSS3</p>\n",
      "<img src=\"html5.jpg\" width=\"300\"/>\n",
      "</section>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "資料型態     =  <class 'bs4.element.ResultSet'>\n",
      "串列長度     =  1\n",
      "元素資料型態 =  <class 'bs4.element.Tag'>\n",
      "元素內容     =  洪錦魁\n"
     ]
    }
   ],
   "source": [
    "# ch5_8.py\n",
    "import bs4\n",
    "\n",
    "# 打開 myhtml.html 並利用 utf-8 解析\n",
    "htmlFile = open('myhtml.html', encoding='utf-8')\n",
    "# 利用 bs4 lxml 方法解析，並存入 bs4 物件\n",
    "objSoup = bs4.BeautifulSoup(htmlFile, 'lxml')\n",
    "print(objSoup)\n",
    "# 找尋 bs4 物件內 id = 'author' 的資料\n",
    "objTag = objSoup.select('#author')\n",
    "\n",
    "print(\"\\n資料型態     = \", type(objTag))          # 列印資料型態\n",
    "print(\"串列長度     = \", len(objTag))           # 列印串列長度\n",
    "print(\"元素資料型態 = \", type(objTag[0]))       # 列印元素資料型態\n",
    "print(\"元素內容     = \", objTag[0].getText())   # 列印元素內容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 將解析的串列元素傳給 str()，並查看元素 type\n",
    "\n",
    "```python\n",
    "# 標籤字串\n",
    "print('列出串列元素的資料型態: ', type(objTag[0]))\n",
    "#純字串\n",
    "print('列出 str()轉換後的串列元素型態: ', type(str(objTag[0])))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "列出串列元素的資料型態:  <class 'bs4.element.Tag'>\n",
      "<h1 id=\"author\">洪錦魁</h1>\n",
      "列出 str()轉換後的串列元素型態:  <class 'str'>\n",
      "<h1 id=\"author\">洪錦魁</h1>\n"
     ]
    }
   ],
   "source": [
    "# ch5_9.py\n",
    "import bs4\n",
    "\n",
    "# 打開 myhtml.html 並利用 utf-8 解析\n",
    "htmlFile = open('myhtml.html', encoding='utf-8')\n",
    "# 利用 bs4 lxml 方法解析，並存入 bs4 物件\n",
    "objSoup = bs4.BeautifulSoup(htmlFile, 'lxml')\n",
    "# 找尋 bs4 物件內 id = 'author' 的資料\n",
    "objTag = objSoup.select('#author')\n",
    "# 標籤字串\n",
    "print('列出串列元素的資料型態: ', type(objTag[0]))\n",
    "print(objTag[0])\n",
    "# 純字串\n",
    "print('列出 str()轉換後的串列元素型態: ', type(str(objTag[0])))\n",
    "print(str(objTag[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. 將 attrs 屬性應用在串列元素，列出字典結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'author'}\n"
     ]
    }
   ],
   "source": [
    "# ch5_10.py\n",
    "import bs4\n",
    "\n",
    "# 打開 myhtml.html 並利用 utf-8 解析\n",
    "htmlFile = open('myhtml.html', encoding='utf-8')\n",
    "# 利用 bs4 lxml 方法解析，並存入 bs4 物件\n",
    "objSoup = bs4.BeautifulSoup(htmlFile, 'lxml')\n",
    "# 找尋 bs4 物件內 id = 'author' 的資料\n",
    "objTag = objSoup.select('#author')\n",
    "# 列出 str()轉換後的串列元素型態，並顯示字典元素\n",
    "print(str(objTag[0].attrs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. 子標籤\n",
    "\n",
    "目的: 搜尋 Tag: p，最後列出串列內容，而不包含子標籤 second-Tag: strong \n",
    "```python\n",
    "<p>2015/2016年<strong>洪錦魁</strong>一個人到南極</p>\n",
    "<p>本書講解網頁設計使用HTML5+CSS3</p>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "含<p>標籤的串列長度 =  2\n",
      "<p>2015/2016年<strong>洪錦魁</strong>一個人到南極</p>\n",
      "2015/2016年洪錦魁一個人到南極\n",
      "2015/2016年洪錦魁一個人到南極 \n",
      "\n",
      "<p>本書講解網頁設計使用HTML5+CSS3</p>\n",
      "本書講解網頁設計使用HTML5+CSS3\n",
      "本書講解網頁設計使用HTML5+CSS3 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ch5_11.py\n",
    "import bs4\n",
    "\n",
    "# 打開 myhtml.html 並利用 utf-8 解析\n",
    "htmlFile = open('myhtml.html', encoding='utf-8')\n",
    "# 利用 bs4 lxml 方法解析，並存入 bs4 物件\n",
    "objSoup = bs4.BeautifulSoup(htmlFile, 'lxml')\n",
    "# 找尋 bs4 物件內 Tag <p> 的資料\n",
    "pObjTag = objSoup.select('p')\n",
    "print(\"含<p>標籤的串列長度 = \", len(pObjTag))\n",
    "for pObj in pObjTag:\n",
    "    print(str(pObj))              # 內部有子標籤<strong>字串\n",
    "    print(pObj.getText())         # 沒有子標籤\n",
    "    print(pObj.text, '\\n')              # 沒有子標籤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. 標籤字串的 get()\n",
    "\n",
    "搜尋 img 內部的標籤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "含<img>標籤的串列長度 =  3\n",
      "----------------------------------------------------------------------\n",
      "<img src=\"hung.jpg\" width=\"100\"/>\n",
      "\n",
      "<img src=\"travel.jpg\" width=\"300\"/>\n",
      "\n",
      "<img src=\"html5.jpg\" width=\"300\"/>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ch5_12.py\n",
    "import bs4\n",
    "\n",
    "# 打開 myhtml.html 並利用 utf-8 解析\n",
    "htmlFile = open('myhtml.html', encoding='utf-8')\n",
    "# 利用 bs4 lxml 方法解析，並存入 bs4 物件\n",
    "objSoup = bs4.BeautifulSoup(htmlFile, 'lxml')\n",
    "# 找尋 bs4 物件內 Tag <img> 的資料\n",
    "imgTag = objSoup.select('img')\n",
    "print(\"含<img>標籤的串列長度 = \", len(imgTag))\n",
    "print('-' * 70)\n",
    "# 了解有哪一些 <img> Tag 在這之中 \n",
    "for img in imgTag:              \n",
    "    print(img)\n",
    "    # 會發現 img 內不會有 text\n",
    "    print(img.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. 擴充取得 myhtml.html 的所有圖檔\n",
    "\n",
    "```python\n",
    "<img src=\"hung.jpg\" width=\"100\"/>\n",
    "hung.jpg\n",
    "<img src=\"travel.jpg\" width=\"300\"/>\n",
    "travel.jpg\n",
    "<img src=\"html5.jpg\" width=\"300\"/>\n",
    "html5.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "含<img>標籤的串列長度 =  3\n",
      "<img src=\"hung.jpg\" width=\"100\"/>\n",
      "hung.jpg\n",
      "hung.jpg\n",
      "<img src=\"travel.jpg\" width=\"300\"/>\n",
      "travel.jpg\n",
      "travel.jpg\n",
      "<img src=\"html5.jpg\" width=\"300\"/>\n",
      "html5.jpg\n",
      "html5.jpg\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "\n",
    "htmlFile = open('myhtml.html', encoding = 'utf-8')\n",
    "objSoup = bs4.BeautifulSoup(htmlFile, 'lxml')\n",
    "objTag = objSoup.select('img')\n",
    "print('含<img>標籤的串列長度 = ', len(imgTag))\n",
    "for data in objTag: \n",
    "    print(data)\n",
    "    # 有兩種不同方法可以取得\n",
    "    print(data.get('src'))\n",
    "    print(data['src'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 18. 其他 HTML 檔案解析: 爬蟲台灣最健康大學排名\n",
    "\n",
    "EX: ch5_2_1.html 檔案\n",
    "```python\n",
    "<!doctype html>\n",
    "<html>\n",
    "<head>\n",
    "   <meta charset=\"utf-8\">\n",
    "   <title>ch5_2_1.html</title> \n",
    "</head>\n",
    "<body>\n",
    "<h1>台灣旅遊景點排名</h1>\n",
    "<ol type=\"a\">\n",
    "   <li>故宮博物院</li><li>日月潭</li><li>阿里山</li>\n",
    "</ol>\n",
    "<h2>台灣夜市排名</h2>\n",
    "<ol type=\"A\">\n",
    "   <li>士林夜市</li><li>永康夜市</li><li>逢甲夜市</li>\n",
    "</ol>\n",
    "<h2>台灣人口排名</h2>\n",
    "<ol type=\"i\">\n",
    "   <li>新北市</li><li>台北市</li><li>桃園市</li>\n",
    "</ol>\n",
    "<h2>台灣最健康大學排名</h2>\n",
    "<ol type=\"I\">\n",
    "   <li>明志科大</li><li>台灣體院</li><li>台北體院</li>\n",
    "</ol>\n",
    "</body>\n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "台灣最健康大學排名\n",
      "明志科大\n",
      "台灣體院\n",
      "台北體院\n"
     ]
    }
   ],
   "source": [
    "import bs4, requests\n",
    "\n",
    "url = 'ch5_2_1.html'\n",
    "# 打開 myhtml.html 並利用 utf-8 解析\n",
    "htmlFile = open(url, encoding = 'utf-8')\n",
    "# 利用 bs4 lxml 方法解析，並存入 bs4 物件\n",
    "objSoup = bs4.BeautifulSoup(htmlFile, 'lxml')\n",
    "# print(objSoup)\n",
    "# 找尋 bs4 物件內全部 Tag <h2> 的資料\n",
    "titleTag = objSoup.find_all('h2')\n",
    "print(titleTag[2].text)\n",
    "# 找尋 objSoup 中 Tag <ol> type = 'I'\n",
    "itemobj = objSoup.find('ol', type = 'I')\n",
    "# 找 itemobj 內 Tag <li> 的物件 \n",
    "items = itemobj.find_all('li')\n",
    "# items = itemobj.find('li')\n",
    "\n",
    "for item in items:\n",
    "    print(item.getText())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. 爬取自定義的 HTML 資料: 爬取國家首都資料，並以字典列出(國家:首都)，認識 zip() 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country =  ['美國首都', '日本首都', '法國首都']\n",
      "City =  ['Washington', 'Tokyo', 'Paris']\n",
      "{'美國首都': 'Washington', '日本首都': 'Tokyo', '法國首都': 'Paris'}\n"
     ]
    }
   ],
   "source": [
    "import bs4, requests\n",
    "\n",
    "url = 'ch5_2_2.html'\n",
    "# 打開 myhtml.html 並利用 utf-8 解析\n",
    "htmlFile = open(url, encoding = 'utf-8')\n",
    "# 利用 bs4 lxml 方法解析，並存入 bs4 物件\n",
    "objSoup = bs4.BeautifulSoup(htmlFile, 'lxml')\n",
    "# print(objSoup)\n",
    "\n",
    "# 先找國家首都\n",
    "mycountry = []\n",
    "capobj = objSoup.find('dl')\n",
    "captag = capobj.find_all('dd')\n",
    "# print(captag)\n",
    "for cap in captag:\n",
    "    mycountry.append(cap.getText())\n",
    "print('Country = ', mycountry)\n",
    "\n",
    "# 再找城市\n",
    "mycity = []\n",
    "cityobj = objSoup.find('dl')\n",
    "citytag = cityobj.find_all('dt')\n",
    "for city in citytag:\n",
    "    mycity.append(city.getText())\n",
    "print('City = ', mycity)\n",
    "\n",
    "# 合併成字典 zip()\n",
    "data = dict(zip(mycountry, mycity))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. 爬取表格文件(國家: 河流)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tr><td>長江</td><td>中國</td><td>亞洲</td></tr>\n",
      "<tr><td>尼羅河</td><td>埃及</td><td>非洲</td></tr>\n",
      "<tr><td>亞馬遜河</td><td>巴西</td><td>南美洲</td></tr>\n",
      "Country:  ['中國', '埃及', '巴西']\n",
      "River:  ['長江', '尼羅河', '亞馬遜河']\n",
      "----------------------------------------------------------------------\n",
      "{'中國': '長江', '埃及': '尼羅河', '巴西': '亞馬遜河'}\n"
     ]
    }
   ],
   "source": [
    "import bs4, requests\n",
    "\n",
    "url = 'ch5_2_3.html'\n",
    "htmlFile = open(url, encoding = 'utf-8')\n",
    "objSoup = bs4.BeautifulSoup(htmlFile, 'lxml')\n",
    "\n",
    "# 1. 河流名稱\n",
    "\n",
    "# 創造一個 list \n",
    "myriver = []\n",
    "# 在 html 內找元素(table) & 次元素 (tbody)\n",
    "tableobj = objSoup.find('table').find('tbody')\n",
    "# 在向下一層找 全部次元素 (tr)\n",
    "tabletag = riverobj.find_all('tr')\n",
    "# 再將每一 row 區分，找出全部的 Tag <td>，並找出河流td[0]\n",
    "for river in tabletag:\n",
    "    river = river.find_all('td')\n",
    "    myriver.append(river[0].getText())\n",
    "\n",
    "# 2. 國家\n",
    "mycountry = []\n",
    "tableobj = objSoup.find('table').find('tbody')\n",
    "tabletag = countryobj.find_all('tr')\n",
    "for country in tabletag:\n",
    "    country = country.find_all('td')\n",
    "    mycountry.append(country[1].getText())\n",
    "\n",
    "# 3. 合併成字典(國家:河流)\n",
    "print('Country: ', mycountry)\n",
    "print('River: ', myriver)\n",
    "print('-' * 70)\n",
    "data = dict(zip(mycountry, myriver))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country:  ['中國', '埃及', '巴西']\n",
      "River:  ['長江', '尼羅河', '亞馬遜河']\n",
      "----------------------------------------------------------------------\n",
      "{'中國': '長江', '埃及': '尼羅河', '巴西': '亞馬遜河'}\n"
     ]
    }
   ],
   "source": [
    "import bs4, requests\n",
    "\n",
    "url = 'ch5_2_3.html'\n",
    "htmlFile = open(url, encoding = 'utf-8')\n",
    "objSoup = bs4.BeautifulSoup(htmlFile, 'lxml')\n",
    "\n",
    "# 1. 河流名稱/ 國家名稱\n",
    "\n",
    "# 創造一個 list \n",
    "myriver = []\n",
    "mycountry = []\n",
    "# 在 html 內找元素(table) & 次元素 (tbody)\n",
    "tableobj = objSoup.find('table').find('tbody')\n",
    "# 在向下一層找 全部次元素 (tr)\n",
    "tabletag = riverobj.find_all('tr')\n",
    "# 再將每一 row 區分，找出全部的 Tag <td>，並找出河流td[0]\n",
    "for river in tabletag:\n",
    "    river = river.find_all('td')\n",
    "    myriver.append(river[0].getText())\n",
    "    mycountry.append(river[1].getText())\n",
    "\n",
    "# 3. 合併成字典(國家:河流)\n",
    "print('Country: ', mycountry)\n",
    "print('River: ', myriver)\n",
    "print('-' * 70)\n",
    "data = dict(zip(mycountry, myriver))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
